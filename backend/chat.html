<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sola AI - Modern Chat</title>
    <style>
        body {
            background: #1a1a1a;
            color: #ffffff;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto;
            margin: 0;
            height: 100vh;
        }
        .chat-container {
            display: flex;
            flex-direction: column;
            height: 100vh;
            max-width: 600px;
            margin: 0 auto;
            background: #181818;
            box-shadow: 0 0 16px #0008;
        }
        .chat-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 18px 20px;
            background: #23272f;
            border-bottom: 1px solid #222;
        }
        .user-info {
            font-weight: 600;
            font-size: 1.1em;
            color: #b3d1ff;
        }
        .logout-btn {
            background: #2a2a2a;
            color: #fff;
            border: none;
            border-radius: 8px;
            padding: 8px 18px;
            cursor: pointer;
            font-size: 1em;
            transition: background 0.2s;
        }
        .logout-btn:hover {
            background: #3b4a5c;
        }
        .messages-container {
            flex: 1;
            overflow-y: auto;
            padding: 20px 10px 20px 10px;
            display: flex;
            flex-direction: column;
            gap: 16px;
            background: #181818;
        }
        .message-user {
            align-self: flex-end;
            background: #3b4a5c;
            border-radius: 18px 18px 4px 18px;
            padding: 12px 16px;
            max-width: 70%;
            word-break: break-word;
            font-size: 1.08em;
            box-shadow: 0 2px 8px #0003;
        }
        .message-ai {
            align-self: flex-start;
            background: #2a2a2a;
            border-radius: 18px 18px 18px 4px;
            padding: 12px 16px;
            max-width: 70%;
            word-break: break-word;
            font-size: 1.08em;
            box-shadow: 0 2px 8px #0003;
        }
        .input-container {
            display: flex;
            padding: 20px;
            background: #242424;
            border-top: 1px solid #333;
            align-items: center;
            justify-content: center;
        }
        .voice-btn {
            background: #4a9eff;
            border: none;
            border-radius: 50%;
            width: 60px;
            height: 60px;
            font-size: 24px;
            cursor: pointer;
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: background 0.2s;
        }
        .voice-btn.recording {
            background: #ff4757;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        .voice-status {
            position: fixed;
            bottom: 90px;
            left: 50%;
            transform: translateX(-50%);
            background: #23272f;
            color: #fff;
            padding: 10px 24px;
            border-radius: 24px;
            font-size: 1.1em;
            display: none;
            z-index: 1001;
            box-shadow: 0 2px 8px #0005;
        }
        .voice-status.processing {
            background: #ff9500;
        }
        .voice-status.error {
            background: #ff4757;
        }
        .voice-status.success {
            background: #2ed573;
        }
        .voice-btn.interrupting {
            background: #ff9500;
            animation: pulse 0.5s ease-in-out;
        }
        .voice-status.interrupting {
            background: #ff9500;
        }
        @media (max-width: 700px) {
            .chat-container {
                max-width: 100vw;
                border-radius: 0;
            }
            .auth-modal-content {
                min-width: 90vw;
            }
        }

        /* --- Auth Modal CSS (Fix #1) --- */
        .auth-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 2000;
        }

        .auth-modal-content {
            background: #2a2a2a;
            padding: 40px;
            border-radius: 12px;
            min-width: 400px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);
        }

        .auth-modal-content h2 {
            color: #b3d1ff;
            margin-bottom: 24px;
            text-align: center;
        }

        .auth-modal-content input {
            width: 100%;
            padding: 12px;
            margin-bottom: 16px;
            border: 1px solid #444;
            border-radius: 8px;
            background: #1a1a1a;
            color: #fff;
            font-size: 1em;
        }

        .auth-modal-content button {
            width: 100%;
            padding: 12px;
            background: #4a9eff;
            border: none;
            border-radius: 8px;
            color: white;
            font-size: 1em;
            cursor: pointer;
            transition: background 0.2s;
        }

        .auth-modal-content button:hover {
            background: #3b8ae0;
        }

        /* Loading overlay */
        .loading-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background: rgba(0,0,0,0.85);
            display: flex;
            align-items: center;
            justify-content: center;
            color: #ffffff;
            font-size: 1.3em;
            z-index: 3000;
        }
        .spinner {
            border: 6px solid #3b3b3b;
            border-top: 6px solid #4a9eff;
            border-radius: 50%;
            width: 48px;
            height: 48px;
            animation: spin 1s linear infinite;
            margin-right: 16px;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="chat-header">
            <div class="user-info" id="user-info">User</div>
            <button class="logout-btn" id="logout-btn">Logout</button>
        </div>
        <div class="messages-container" id="messages"></div>
        <div class="input-container">
            <button class="voice-btn" id="voice-btn">📞</button>
        </div>
    </div>
    <div class="auth-modal" id="auth-modal" style="display:none;">
        <div class="auth-modal-content">
            <h2>Login to Sola AI</h2>
            <input type="email" id="login-email" placeholder="Email" required>
            <input type="password" id="login-password" placeholder="Password" required>
            <button id="login-btn">Login</button>
            <div id="login-error" style="color:#ff4757; font-size:0.98em;"></div>
        </div>
    </div>
    <div class="voice-status" id="voice-status">🎤 Recording...</div>
    <!-- 🔄 Loading overlay shown while backend warms intimacy scaffold -->
    <div class="loading-overlay" id="loading-overlay" style="display:none;">
        <div style="display:flex; align-items:center;">
            <div class="spinner"></div>
            <span>Preparing your conversation...</span>
        </div>
    </div>
    <script>
        // --- Global Config ---
        const MEMORY_LAYER_ENABLED = false; // Disable memory layer & related UI
        // --- Auth & State ---
        let authToken = localStorage.getItem('auth_token');
        let username = localStorage.getItem('username') || 'User';
        let ws = null;
        let clientId = localStorage.getItem('client_id') || (Math.random().toString(36).slice(2));
        localStorage.setItem('client_id', clientId);

        // --- NEW: Voice State Machine ---
        const VoiceState = {
            IDLE: 'IDLE',
            RECORDING: 'RECORDING',
            WAITING: 'WAITING',
            PROCESSING: 'PROCESSING',
            AI_SPEAKING: 'AI_SPEAKING'
        };
        let currentVoiceState = VoiceState.IDLE;
        
        // --- NEW: Recording timeout protection (Fix #4) ---
        let recordingTimeout = null;
        const MAX_RECORDING_TIME = 30000; // 30 seconds

        // --- UI Elements ---
        const authModal = document.getElementById('auth-modal');
        const loginBtn = document.getElementById('login-btn');
        const loginError = document.getElementById('login-error');
        const userInfo = document.getElementById('user-info');
        const logoutBtn = document.getElementById('logout-btn');
        const messagesDiv = document.getElementById('messages');
        const voiceBtn = document.getElementById('voice-btn');
        const voiceStatus = document.getElementById('voice-status');
        const loadingOverlay = document.getElementById('loading-overlay');

        function setVoiceState(newState) {
            // Enhanced state transition logging (Fix #3)
            if (currentVoiceState === newState) {
                // console.log(`State transition ignored: already in ${newState}`);
                return;
            }
            const timestamp = new Date().toISOString().substr(11, 12);
            console.log(`[${timestamp}] State transition: ${currentVoiceState} -> ${newState}`);
            
            // Add validation
            if (!Object.values(VoiceState).includes(newState)) {
                console.error(`Invalid state: ${newState}`);
                return;
            }
            currentVoiceState = newState;

            switch (newState) {
                case VoiceState.IDLE:
                    voiceBtn.disabled = false;
                    voiceBtn.innerHTML = '📞';
                    voiceBtn.classList.remove('recording', 'interrupting');
                    voiceStatus.style.display = 'none';
                    break;
                case VoiceState.RECORDING:
                    voiceBtn.disabled = false;
                    voiceBtn.innerHTML = '⏹';
                    voiceBtn.classList.add('recording');
                    voiceStatus.textContent = '🎤 Recording...';
                    voiceStatus.className = 'voice-status';
                    voiceStatus.style.display = 'block';
                    break;
                case VoiceState.WAITING:
                    voiceBtn.disabled = false;
                    voiceBtn.innerHTML = '🤔';
                    voiceBtn.classList.remove('recording');
                    voiceStatus.textContent = 'Sola is thinking...';
                    voiceStatus.className = 'voice-status processing';
                    voiceStatus.style.display = 'block';
                    break;
                case VoiceState.PROCESSING:
                    voiceBtn.disabled = true;
                    voiceBtn.innerHTML = '🔄';
                    voiceBtn.classList.remove('recording');
                    voiceStatus.textContent = '🔄 Processing...';
                    voiceStatus.className = 'voice-status processing';
                    voiceStatus.style.display = 'block';
                    break;
                case VoiceState.AI_SPEAKING:
                    voiceBtn.disabled = false;
                    voiceBtn.innerHTML = '🛑';
                    voiceBtn.classList.add('interrupting');
                    voiceStatus.style.display = 'none';
                    break;
            }
        }

        // --- Auth Modal Logic ---
        function showAuthModal() {
            authModal.style.display = 'flex';
        }
        function hideAuthModal() {
            authModal.style.display = 'none';
        }
        function showChatInterface() {
            hideAuthModal();
            document.querySelector('.chat-container').style.display = 'flex';
            userInfo.textContent = username;
            if (MEMORY_LAYER_ENABLED) {
                showLoading(true); // Only show if memory layer is enabled
            }
            connectWS();
            loadChatHistory();
        }
        function handleLogin() {
            const email = document.getElementById('login-email').value;
            const password = document.getElementById('login-password').value;
            loginError.textContent = '';
            fetch('/auth/signin', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ email, password })
            })
            .then(res => res.json().then(data => ({ ok: res.ok, data })))
            .then(({ ok, data }) => {
                if (ok) {
                    authToken = data.data.session.access_token;
                    username = data.data.user.email;
                    localStorage.setItem('auth_token', authToken);
                    localStorage.setItem('username', username);
                    showChatInterface();
                } else {
                    const errorMessage = data.detail || 'Login failed';
                    loginError.textContent = errorMessage;
                    if (errorMessage.includes('Email not confirmed')) {
                        loginError.textContent += ' Please check your email and click the confirmation link.';
                    }
                }
            })
            .catch(err => {
                loginError.textContent = 'Login error: ' + err.message;
            });
        }
        loginBtn.onclick = handleLogin;
        logoutBtn.onclick = function() {
            localStorage.removeItem('auth_token');
            localStorage.removeItem('username');
            location.reload();
        };

        // --- Show Auth Modal if not logged in ---
        if (!authToken) {
            showAuthModal();
            document.querySelector('.chat-container').style.display = 'none';
        } else {
            showChatInterface();
        }

        // --- Chat Message Functions ---
        function addMessage(type, content, isTemporary = false) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message-${type}`;
            messageDiv.textContent = content;
            if (isTemporary) messageDiv.id = 'temp-message';
            messagesDiv.appendChild(messageDiv);
            scrollToBottom();
        }
        function updateLastMessage(newContent) {
            const tempMsg = document.getElementById('temp-message');
            if (tempMsg) {
                console.log('🔄 Updating temp message from:', tempMsg.textContent, 'to:', newContent);
                tempMsg.textContent = newContent;
                tempMsg.removeAttribute('id'); // Remove temp-message ID
                tempMsg.setAttribute('data-permanent', 'true'); // Mark as permanent
                console.log('✅ User message made permanent');
            } else {
                console.log('❌ No temp message found to update');
                // Fallback: add the message if temp message is missing
                addMessage('user', newContent);
            }
        }
        function appendToLastAIMessage(content) {
            const messages = document.querySelectorAll('.message-ai');
            const lastAI = messages[messages.length - 1];
            if (lastAI) {
                lastAI.textContent += content;
            } else {
                addMessage('ai', content);
            }
        }
        function scrollToBottom() {
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        function clearMessages() {
            messagesDiv.innerHTML = '';
        }

        // --- Chat History ---
        async function loadChatHistory() {
            try {
                const response = await fetch('/chats?token=' + authToken);
                const data = await response.json();
                clearMessages();
                // Sort chats by creation date to ensure proper order
                data.chats.sort((a, b) => new Date(a.created_at) - new Date(b.created_at));
                data.chats.forEach(chat => {
                    addMessage('user', chat.user_message);
                    addMessage('ai', chat.ai_response);
                });
                // Remove any duplicates that might have been created
                removeDuplicateMessages();
            } catch (error) {
                console.error('Failed to load chat history:', error);
            }
        }

        // --- Advanced Voice Streaming Logic (from index.html, renamed) ---
        let streamingSession = null;
        let audioContext = null;
        let processor = null;

        async function startRecording() {
            if (currentVoiceState !== VoiceState.IDLE && currentVoiceState !== VoiceState.AI_SPEAKING) {
                console.warn(`Attempted to record from invalid state: ${currentVoiceState}`);
                return;
            }
            
            // Clear any previous temp messages and add new one
            const tempMsg = document.getElementById('temp-message');
            if (tempMsg) tempMsg.remove();
            addMessage('user', '🎤 Recording...', true);

            setVoiceState(VoiceState.RECORDING);
            await startStreamingTest();

            // Add recording timeout (Fix #4)
            recordingTimeout = setTimeout(() => {
                if (currentVoiceState === VoiceState.RECORDING) {
                    console.warn('Recording timeout reached, stopping automatically');
                    stopStreamingTest();
                }
            }, MAX_RECORDING_TIME);
        }

        async function startStreamingTest() {
            try {
                streamingSession = { chunks: [], startTime: Date.now() };
                ws.send(JSON.stringify({
                    type: 'audio_stream_start',
                    config: { sample_rate: 16000, channels: 1, format: 'pcm' }
                }));
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                processor = audioContext.createScriptProcessor(1024, 1, 1);
                processor.onaudioprocess = (event) => {
                    if (currentVoiceState !== VoiceState.RECORDING) return;
                    const inputBuffer = event.inputBuffer;
                    const audioData = inputBuffer.getChannelData(0);
                    const pcmData = new Int16Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        const sample = Math.max(-32768, Math.min(32767, Math.round(audioData[i] * 32767)));
                        pcmData[i] = sample;
                    }
                    const rawPcmBytes = new Uint8Array(pcmData.buffer);
                    const base64Audio = btoa(String.fromCharCode(...rawPcmBytes));
                    if (ws.readyState === WebSocket.OPEN) {
                        ws.send(JSON.stringify({
                            type: 'audio_chunk',
                            audio_data: base64Audio,
                            timestamp: Date.now(),
                            format: 'raw_pcm',
                            sample_rate: 16000,
                            channels: 1
                        }));
                    }
                };
                source.connect(processor);
                processor.connect(audioContext.destination);
                streamingSession.stream = stream;
            } catch (error) {
                alert(`Voice recording failed: ${error.message}`);
                setVoiceState(VoiceState.IDLE);
            }
        }

        function stopStreamingTest(sendStreamEnd = true) {
            // Clear timeout (Fix #4)
            if (recordingTimeout) {
                clearTimeout(recordingTimeout);
                recordingTimeout = null;
            }

            if (!streamingSession) return;

            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (audioContext) {
                audioContext.close().catch(console.warn);
                audioContext = null;
            }
            if (streamingSession.stream) {
                streamingSession.stream.getTracks().forEach(track => track.stop());
            }
            if (sendStreamEnd && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'audio_stream_end' }));
                setVoiceState(VoiceState.WAITING);
            } else if (!sendStreamEnd) {
                setVoiceState(VoiceState.IDLE);
            }
            streamingSession = null;
        }

        // --- Voice Button On-Click Logic (State Machine) ---
        voiceBtn.onclick = async function() {
            switch (currentVoiceState) {
                case VoiceState.IDLE:
                    await startRecording();
                    break;
                case VoiceState.RECORDING:
                    stopStreamingTest();
                    break;
                case VoiceState.WAITING:
                case VoiceState.AI_SPEAKING:
                    console.log('🛑 Interrupting AI speech...');
                    // Stop frontend audio immediately and send backend message
                    interruptAISpeech();
                    ws.send(JSON.stringify({ type: 'interrupt_speech' }));
                    // Immediately start recording for seamless barge-in
                    await startRecording();
                    break;
                case VoiceState.PROCESSING:
                    // Button is disabled, do nothing
                    break;
            }
        };

        function interruptAISpeech() {
            console.log('🛑 Frontend: Interrupting AI speech');
            if (currentPlaybackSession) {
                currentPlaybackSession.stop(); // Use the new stop method
                currentPlaybackSession = null;
            }
            audioStreamEnded = false; // Reset global flag
            setVoiceState(VoiceState.IDLE); // Go to IDLE before transitioning to RECORDING
        }

        // --- WebSocket & Voice Logic (REFACTORED for Playback Sessions) ---
        let currentPlaybackSession = null;
        let audioStreamEnded = false; // Global flag to know if backend is done

        function createPlaybackSession() {
            const session = {
                id: Date.now(),
                audioContext: new (window.AudioContext || window.webkitAudioContext)(),
                bufferQueue: [],
                isPlaying: false,
                
                play: function() {
                    if (this.bufferQueue.length === 0 || this.isPlaying) return;
                    
                    this.isPlaying = true;
                    const chunk = this.bufferQueue.shift();
                    
                    // If context is closed, stop.
                    if (this.audioContext.state === 'closed') {
                        this.isPlaying = false;
                        return;
                    }

                    this.audioContext.decodeAudioData(chunk.buffer.slice(chunk.byteOffset, chunk.byteOffset + chunk.byteLength), 
                        (audioBuffer) => {
                            if (this.audioContext.state === 'closed' || currentPlaybackSession !== this) {
                                console.log(`Orphaned audio chunk from session ${this.id} will not be played.`);
                                return;
                            }
                            const source = this.audioContext.createBufferSource();
                            source.buffer = audioBuffer;
                            source.connect(this.audioContext.destination);
                            source.onended = () => {
                                // CRITICAL CHECK: only proceed if this is still the active session
                                if (currentPlaybackSession === this) {
                                    this.isPlaying = false;
                                    this.play(); // Attempt to play next chunk
                                }
                            };
                            source.start(0);
                        }, 
                        (err) => {
                            console.error('Audio decode error:', err);
                            if (currentPlaybackSession === this) {
                                this.isPlaying = false;
                            }
                        }
                    );
                },

                addChunk: function(bytes) {
                    this.bufferQueue.push(bytes);
                    if (!this.isPlaying) {
                        this.play();
                    }
                },

                stop: function() {
                    if (this.audioContext && this.audioContext.state !== 'closed') {
                        this.audioContext.close().catch(e => console.warn("Error closing audio context on stop:", e));
                    }
                },

                isFinished: function() {
                    return audioStreamEnded && !this.isPlaying && this.bufferQueue.length === 0;
                }
            };
            return session;
        }

        function checkAndFinalizeSpeech() {
            if (currentPlaybackSession && currentPlaybackSession.isFinished()) {
                console.log(`🔇 AI speech playback concluded for session ${currentPlaybackSession.id}.`);
                currentPlaybackSession.stop();
                currentPlaybackSession = null;
                audioStreamEnded = false;
                setVoiceState(VoiceState.IDLE);
            }
        }
        
        // This is now just a simple observer, called by playback events
        setInterval(checkAndFinalizeSpeech, 100);


        function handleAudioChunk(base64Chunk) {
            if (!currentPlaybackSession) {
                currentPlaybackSession = createPlaybackSession();
                // When a new session starts, ensure we are in the speaking state
                setVoiceState(VoiceState.AI_SPEAKING);
            }
            const binary = atob(base64Chunk);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) {
                bytes[i] = binary.charCodeAt(i);
            }
            currentPlaybackSession.addChunk(bytes);
        }

        function endAudioStream() {
            console.log('Backend signaled end of audio stream.');
            audioStreamEnded = true;
            // The checkAndFinalizeSpeech interval will handle the rest
        }

        function connectWS() {
            if (ws) ws.close();
            ws = new WebSocket(`ws://${window.location.host}/ws/${clientId}?token=${authToken}`);
            ws.onopen = () => {};
            
            // WebSocket Error Handling Enhancement (Fix #2)
            ws.onclose = () => {
                console.log('WebSocket closed');
                setVoiceState(VoiceState.IDLE);
            };
            ws.onerror = (e) => { 
                console.error('WebSocket error:', e); 
                setVoiceState(VoiceState.IDLE);
            };

            ws.onmessage = (event) => {
                const msg = JSON.parse(event.data);
                console.log('📨 WebSocket message:', msg.type, msg);
                
                if (currentVoiceState === VoiceState.RECORDING && (msg.type === 'status' && msg.status.includes('speech'))) {
                     voiceStatus.textContent = '🎙️ Speech detected...';
                }

                if (msg.type === 'status') {
                    // Memory-related overlay
                    if (MEMORY_LAYER_ENABLED && msg.status === 'scaffold_warming') {
                        showLoading(true);
                    } else if (MEMORY_LAYER_ENABLED && msg.status === 'scaffold_ready') {
                        showLoading(false);
                    }

                    // Statuses always handled
                    if (msg.status === 'transcription_complete') {
                        updateLastMessage(msg.transcript);
                    } else if (msg.status === 'llm_tts_streaming') {
                        setVoiceState(VoiceState.AI_SPEAKING);
                    } else if (msg.status === 'streaming_complete') {
                        endAudioStream();
                    } else if (msg.status === 'recording_complete') {
                        setVoiceState(VoiceState.WAITING);
                    }
                }
                else if (msg.type === 'token_stream') {
                    console.log('🔄 Token stream received:', msg.content);
                    let lastAI = document.querySelector('.message-ai:last-of-type');
                    if (!lastAI) {
                        console.log('➕ Creating first AI message');
                        addMessage('ai', msg.content);
                    } else {
                        lastAI.textContent += msg.content;
                    }
                    verifyMessageIntegrity();
                }
                else if (msg.type === 'transcript_token') {
                    const tempMsg = document.getElementById('temp-message');
                    if (tempMsg) {
                        console.log('📝 Updating transcript token:', msg.content);
                        tempMsg.textContent = msg.content;
                    }
                }
                else if (msg.type === 'audio_chunk') {
                    handleAudioChunk(msg.audio_data);
                }
                else if (msg.type === 'result') {
                    console.log('🏁 Result received, cleaning up');
                    voiceStatus.style.display = 'none';
                    voiceStatus.className = 'voice-status success';
                    // AI finished speaking
                    setVoiceState(VoiceState.IDLE);
                    // Only remove temp messages that haven't been made permanent
                    const tempMsg = document.getElementById('temp-message');
                    if (tempMsg && !tempMsg.hasAttribute('data-permanent')) {
                        console.log('🗑️ Removing leftover temp message');
                        tempMsg.remove();
                    } else {
                        console.log('✅ No temp message to remove');
                    }
                    if (msg.audio_data) {
                        // Play the final audio file if present (fallback)
                        const audio = new Audio('data:audio/mp3;base64,' + msg.audio_data);
                        audio.play();
                    }
                    endAudioStream();
                    verifyMessageIntegrity();
                }
                else if (msg.type === 'error') {
                    voiceStatus.textContent = '❌ Error: ' + msg.message;
                    voiceStatus.className = 'voice-status error';
                    // AI stopped speaking due to error
                    setVoiceState(VoiceState.IDLE);
                    setTimeout(() => {
                        voiceStatus.style.display = 'none';
                    }, 3000);
                    if (msg.message === 'scaffold_warm_failed') {
                        if (MEMORY_LAYER_ENABLED) {
                            showLoading(false);
                        }
                    }
                }
                else if (msg.type === 'speech_interrupted' || msg.type === 'interruption_result') {
                    console.log('Backend confirmed interruption.');
                    // State is already handled by the click handler, this is just a confirmation.
                }
            };
        }

        // --- Finalize Messages after AI response ---
        function finalizeMessages(transcript, ai_response) {
            // Remove any temporary recording message
            const tempMsg = document.getElementById('temp-message');
            if (tempMsg) {
                tempMsg.remove();
            }
            // Check if we already have these exact messages to prevent duplicates
            const messages = messagesDiv.children;
            const lastUserMsg = messages[messages.length - 2]; // Second to last
            const lastAIMsg = messages[messages.length - 1];   // Last
            // Only add user message if it's not already there
            if (!lastUserMsg || !lastUserMsg.textContent.includes(transcript)) {
                addMessage('user', transcript || '🎤 Voice message');
            }
            // Only add AI message if it's not already there or if it's incomplete
            if (!lastAIMsg || 
                !lastAIMsg.classList.contains('message-ai') || 
                lastAIMsg.textContent !== ai_response) {
                // Remove incomplete AI message if exists
                if (lastAIMsg && lastAIMsg.classList.contains('message-ai') && 
                    lastAIMsg.textContent !== ai_response) {
                    lastAIMsg.remove();
                }
                addMessage('ai', ai_response);
            }
        }

        // Debugging helper
        function debugMessages() {
            console.log('Current messages in DOM:');
            Array.from(messagesDiv.children).forEach((msg, index) => {
                console.log(`${index}: ${msg.className} - "${msg.textContent}"`);
            });
        }

        // Remove duplicate messages after loading chat history
        function removeDuplicateMessages() {
            const messages = Array.from(messagesDiv.children);
            const seen = new Set();
            messages.forEach(msg => {
                const key = `${msg.className}-${msg.textContent}`;
                if (seen.has(key)) {
                    msg.remove();
                } else {
                    seen.add(key);
                }
            });
        }

        function verifyMessageIntegrity() {
            const userMessages = document.querySelectorAll('.message-user');
            const aiMessages = document.querySelectorAll('.message-ai');
            console.log('🔍 Message integrity check:');
            console.log('  User messages:', userMessages.length);
            console.log('  AI messages:', aiMessages.length);
            Array.from(messagesDiv.children).forEach((msg, index) => {
                const type = msg.classList.contains('message-user') ? 'USER' : 'AI';
                const content = msg.textContent.substring(0, 30) + '...';
                const isTemp = msg.id === 'temp-message' ? '(TEMP)' : '';
                const isPermanent = msg.hasAttribute('data-permanent') ? '(PERMANENT)' : '';
                console.log(`  ${index}: ${type} ${isTemp}${isPermanent} - "${content}"`);
            });
        }

        function showLoading(show=true) {
            loadingOverlay.style.display = show ? 'flex' : 'none';
        }
    </script>
</body>
</html> 